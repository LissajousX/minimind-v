# 多模态视觉语言模型数据准备文档

## 1. 概述

多模态视觉语言模型(VLM)的训练需要精心准备的数据集，这些数据集需要同时包含图像和文本信息。本文档详细介绍了基于MiniMind-V项目的多模态数据准备流程，包括数据收集、预处理、格式化和加载等关键步骤。

## 2. 数据集类型

多模态模型训练通常需要两种主要类型的数据集：

### 2.1 预训练数据集

预训练数据集主要用于让模型学习图像描述能力，包含：
- **图像**：各种领域的图片
- **描述文本**：对应图像的详细描述

在MiniMind-V中，预训练数据集保存在：
- 数据文件：`./dataset/pretrain_data.jsonl`
- 图像目录：`./dataset/pretrain_images`

### 2.2 指令微调数据集

指令微调数据集用于让模型学习多轮对话能力，包含：
- **图像**：各种领域的图片
- **对话内容**：包含用户问题和助手回答的多轮对话

在MiniMind-V中，指令微调数据集保存在：
- 数据文件：`./dataset/sft_data.jsonl`
- 图像目录：`./dataset/sft_images`

## 3. 数据格式

### 3.1 JSONL格式

MiniMind-V采用JSONL格式存储数据，每行包含一个JSON对象，代表一个训练样本：

```json
{
  "image": "image1.jpg",  // 图像文件名或路径
  "conversations": [      // 对话内容
    {
      "role": "user",
      "content": "这张<image>图片展示了什么？"
    },
    {
      "role": "assistant",
      "content": "这张图片展示了一只猫正在草地上玩耍。"
    }
  ]
}
```

**关键字段说明**：
- `image`：图像文件名，可以是单个图像或多个图像（用逗号分隔）
- `conversations`：对话内容列表，包含多轮对话
  - `role`：角色，可以是"user"或"assistant"
  - `content`：对话内容，其中`<image>`标记表示图像位置

### 3.2 图像标记

在对话内容中，使用特殊标记`<image>`表示图像位置。在处理时，这个标记会被替换为图像特殊token（如`@@@...@`）：

```python
messages.append({"role": role, "content": turn['content'].replace('<image>', self.image_token)})
```

## 4. 数据预处理流程

### 4.1 数据加载

```python
def load_data(self, path):
    samples = []
    with open(path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            data = json.loads(line.strip())
            samples.append(data)
    return samples
```

### 4.2 对话格式化

对话内容需要转换为模型可处理的格式：

```python
def _create_chat_prompt(self, conversations):
    messages = []
    for i, turn in enumerate(conversations):
        role = 'user' if i % 2 == 0 else 'assistant'
        messages.append({"role": role, "content": turn['content'].replace('<image>', self.image_token)})
    return self.tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False
    )
```

### 4.3 损失掩码生成

为了只在助手回复部分计算损失，需要生成损失掩码：

```python
def _generate_loss_mask(self, input_ids):
    loss_mask = [0] * len(input_ids)
    i = 0
    while i < len(input_ids):
        if input_ids[i:i + len(self.bos_id)] == self.bos_id:
            start = i + len(self.bos_id)
            end = start
            while end < len(input_ids):
                if input_ids[end:end + len(self.eos_id)] == self.eos_id:
                    break
                end += 1
            for j in range(start + 1, min(end + len(self.eos_id) + 1, self.max_length)):
                loss_mask[j] = 1
            i = end + len(self.eos_id) if end < len(input_ids) else len(input_ids)
        else:
            i += 1
    return loss_mask
```

### 4.4 图像处理

图像需要转换为模型可处理的张量格式：

```python
# 在__getitem__方法中处理图像
image_tensors = []
for image_name in image_paths.split(','):
    image_name = image_name.strip()
    image = Image.open(f'{self.images_path}/{image_name}')
    image_tensor = MiniMindVLM.image2tensor(image, self.preprocess)
    image_tensors.append(image_tensor)
image_tensors = torch.stack(image_tensors, dim=0)
```

图像转张量的具体实现：

```python
@staticmethod
def image2tensor(image, processor):
    if image.mode in ['RGBA', 'LA']: image = image.convert('RGB')
    inputs = processor(images=image, return_tensors="pt")['pixel_values']
    return inputs
```

## 5. 数据集类实现

MiniMind-V使用PyTorch的Dataset类实现数据加载：

```python
class VLMDataset(Dataset):
    def __init__(self, jsonl_path, images_path, tokenizer, preprocess=None, max_length=512,
                 image_special_token='@' * 196):
        super().__init__()
        self.samples = self.load_data(jsonl_path)
        self.images_path = images_path
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.preprocess = preprocess
        self.image_token = image_special_token
        self.bos_id = tokenizer('<s>assistant', add_special_tokens=False).input_ids
        self.eos_id = tokenizer('</s>', add_special_tokens=False).input_ids
        
    def __getitem__(self, index: int):
        sample = self.samples[index]
        image_paths = sample['image']
        prompt = self._create_chat_prompt(sample['conversations'])
        input_ids = self.tokenizer(prompt).input_ids[:self.max_length]
        input_ids += [self.tokenizer.pad_token_id] * (self.max_length - len(input_ids))
        loss_mask = self._generate_loss_mask(input_ids)

        X = torch.tensor(input_ids[:-1], dtype=torch.long)
        Y = torch.tensor(input_ids[1:], dtype=torch.long)
        loss_mask = torch.tensor(loss_mask[1:], dtype=torch.long)

        image_tensors = []
        for image_name in image_paths.split(','):
            image_name = image_name.strip()
            image = Image.open(f'{self.images_path}/{image_name}')
            image_tensor = MiniMindVLM.image2tensor(image, self.preprocess)
            image_tensors.append(image_tensor)
        image_tensors = torch.stack(image_tensors, dim=0)

        return X, Y, loss_mask, image_tensors
```

## 6. 数据加载器配置

在训练脚本中，使用PyTorch的DataLoader加载数据：

```python
train_ds = VLMDataset(args.data_path, args.images_path, tokenizer, preprocess=preprocess,
                      image_special_token=model_config.image_special_token,
                      max_length=max_seq_len)
train_sampler = DistributedSampler(train_ds) if ddp else None
train_loader = DataLoader(
    train_ds,
    batch_size=args.batch_size,
    pin_memory=True,
    drop_last=False,
    shuffle=False,
    num_workers=args.num_workers,
    sampler=train_sampler
)
```

## 7. 数据增强技术

为提高模型性能，可以考虑以下数据增强技术：

### 7.1 图像增强

- 随机裁剪、翻转、旋转
- 色彩调整（亮度、对比度、饱和度）
- 随机擦除（Random Erasing）

### 7.2 文本增强

- 同义词替换
- 随机插入、删除或交换词语
- 回译（Back-translation）

## 8. 数据质量控制

高质量的数据对模型性能至关重要，应注意以下几点：

- **图像质量**：清晰度、分辨率、内容多样性
- **文本质量**：描述准确性、语法正确性、内容丰富度
- **图文一致性**：确保文本描述与图像内容相符
- **数据平衡**：不同领域、场景的数据分布均衡

## 9. 数据集规模建议

根据MiniMind-V的经验，推荐以下数据集规模：

- **预训练数据集**：至少10,000个图文对
- **指令微调数据集**：至少5,000个多轮对话样本

## 10. 实用建议

### 10.1 数据存储

- 使用SSD存储数据集，加快读取速度
- 对于大型数据集，考虑使用数据流式加载
- 预先计算并缓存图像特征，减少训练时的计算负担

### 10.2 多GPU训练

- 使用DistributedSampler确保不同GPU处理不同数据
- 调整batch_size和num_workers以优化多GPU训练效率

### 10.3 内存优化

- 使用适当的batch_size避免内存溢出
- 考虑使用混合精度训练减少内存占用
- 使用梯度累积处理大批量数据

## 11. 总结

多模态数据准备是视觉语言模型训练的关键环节。MiniMind-V项目展示了如何通过简洁高效的数据处理流程，构建轻量级但功能强大的多模态模型。通过合理的数据格式设计、精细的预处理步骤和高效的数据加载机制，可以显著提升模型训练效果和推理性能。
