# 多模态视觉语言模型训练详解文档（第三部分）

## 6. 监督微调阶段详解

监督微调(SFT)是多模态模型训练的第二个关键阶段，目标是让模型学习多轮对话能力。本节将详细解析监督微调的完整流程。

### 6.1 监督微调与预训练的区别

监督微调与预训练阶段有几个重要区别：

1. **训练目标不同**：
   - 预训练：学习图像描述能力
   - 微调：学习多轮对话能力，理解用户问题并生成合适回答

2. **数据集不同**：
   - 预训练：图像-描述对
   - 微调：包含用户问题和助手回答的多轮对话

3. **学习率不同**：
   - 预训练：较高（约4e-4）
   - 微调：较低（约1e-6）

4. **序列长度不同**：
   - 预训练：较短（约640）
   - 微调：较长（约1536），以容纳多轮对话

5. **参数冻结策略不同**：
   - 预训练：大部分参数冻结
   - 微调：所有参数可训练

### 6.2 模型初始化

监督微调阶段的模型初始化与预训练有所不同：

```python
def init_model(model_config: VLMConfig):
    tokenizer = AutoTokenizer.from_pretrained('./model/minimind_tokenizer')
    moe_path = '_moe' if model_config.use_moe else ''
    
    # 加载预训练的多模态模型权重（而非纯语言模型）
    ckp = f'./out/pretrain_vlm_{model_config.dim}{moe_path}.pth'

    model = MiniMindVLM(model_config)
    state_dict = torch.load(ckp, map_location=args.device)
    model.load_state_dict(state_dict, strict=False)
    model = model.to(args.device)

    # 注意：微调阶段不冻结任何参数
    # 所有参数都是可训练的

    Logger(f'VLM可训练参数量：{sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.3f} 百万')

    _, preprocess = MiniMindVLM.get_vision_model()
    return model.to(args.device), tokenizer, preprocess
```

#### 6.2.1 关键区别解析

1. **加载预训练模型**：微调阶段加载的是预训练阶段得到的多模态模型权重，而非纯语言模型
   ```python
   ckp = f'./out/pretrain_vlm_{model_config.dim}{moe_path}.pth'
   ```

2. **参数冻结**：微调阶段不冻结任何参数，允许所有参数更新
   - 预训练阶段：`if 'vision_proj' not in name: param.requires_grad = False`
   - 微调阶段：所有参数都保持可训练状态

3. **可训练参数量**：微调阶段的可训练参数量大大增加，通常是整个模型的参数量

### 6.3 数据加载与处理

微调阶段的数据加载与预训练类似，但使用不同的数据集：

```python
train_ds = VLMDataset(args.data_path, args.images_path, tokenizer, preprocess=preprocess,
                      image_special_token=model_config.image_special_token,
                      max_length=max_seq_len)
```

关键参数：
- `args.data_path`：指向`./dataset/sft_data.jsonl`
- `args.images_path`：指向`./dataset/sft_images`
- `max_seq_len`：通常设置为1536，比预训练阶段更长

#### 6.3.1 微调数据格式示例

```json
{
  "image": "cat_playing.jpg",
  "conversations": [
    {
      "role": "user",
      "content": "这张<image>图片中的猫在做什么？"
    },
    {
      "role": "assistant",
      "content": "这张图片中的猫正在草地上玩耍，它似乎在追逐一只蝴蝶。猫的姿势显示它正在跳跃，看起来非常活跃和开心。"
    },
    {
      "role": "user",
      "content": "这只猫是什么品种？"
    },
    {
      "role": "assistant",
      "content": "从图片来看，这只猫似乎是一只橘色虎斑猫（Orange Tabby）。它有典型的橘色毛发和条纹图案。虎斑猫不是特定的品种，而是一种毛色图案，可以出现在多种猫品种中。"
    }
  ]
}
```

### 6.4 优化器与学习率设置

微调阶段的优化器配置与预训练类似，但学习率显著降低：

```python
optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)  # 通常lr=1e-6
scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype in ['float16', 'bfloat16']))
```

#### 6.4.1 学习率选择原因

微调阶段使用较低的学习率（约1e-6）有以下原因：

1. **保留预训练知识**：较低的学习率可以防止模型忘记预训练阶段学到的知识，确保模型在微调阶段能够有效地利用预训练阶段的知识。

2. **避免过拟合**：较低的学习率可以帮助模型避免过拟合，确保模型能够更好地泛化到新的数据上。

3. **提高模型稳定性**：较低的学习率可以帮助模型提高稳定性，确保模型能够更好地处理新的数据和任务。

### 6.5 训练流程

微调阶段的训练流程与预训练类似，但使用不同的数据集和学习率：

```python
for epoch in range(args.epochs):
    model.train()
    total_loss = 0
    for batch in train_dl:
        input_ids, attention_mask, labels = batch
        input_ids, attention_mask, labels = input_ids.to(args.device), attention_mask.to(args.device), labels.to(args.device)
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_dl)}')
```

### 6.6 模型评估

微调阶段的模型评估与预训练类似，但使用不同的数据集和评估指标：

```python
model.eval()
total_correct = 0
with torch.no_grad():
    for batch in val_dl:
        input_ids, attention_mask, labels = batch
        input_ids, attention_mask, labels = input_ids.to(args.device), attention_mask.to(args.device), labels.to(args.device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        logits = outputs.logits
        _, predicted = torch.max(logits, dim=1)
        total_correct += (predicted == labels).sum().item()
accuracy = total_correct / len(val_dl.dataset)
print(f'Validation Accuracy: {accuracy:.4f}')
```

### 6.7 模型保存

微调阶段的模型保存与预训练类似，但使用不同的模型名称和保存路径：

```python
torch.save(model.state_dict(), f'./out/sft_vlm_{model_config.dim}.pth')
